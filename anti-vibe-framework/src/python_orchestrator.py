"""
Python Orchestrator for Data Science / ML Projects
Generates complete ML pipelines with multi-agent coordination
"""

import os
import asyncio
from pathlib import Path
from typing import Dict, List, Any, Optional
from dataclasses import dataclass
from anthropic import Anthropic
import json

# ============================================================================
# CONFIGURATION TYPES
# ============================================================================

@dataclass
class MLProjectConfig:
    """Configuration for ML/Data Science projects"""
    name: str
    description: str
    tech_stack: Dict[str, str]
    features: List[str]
    output_path: str = "./output"
    kaggle_dataset: Optional[str] = None
    kaggle_credentials: Optional[str] = None


@dataclass
class AgentResult:
    """Result from an agent execution"""
    agent_type: str
    files: List[Dict[str, str]]  # [{"path": "...", "content": "..."}]
    success: bool
    output: str
    error: Optional[str] = None


# ============================================================================
# BASE AGENT CLASS
# ============================================================================

class BaseMLAgent:
    """Base class for all ML project agents"""

    def __init__(self, anthropic_client: Anthropic, config: Dict[str, Any]):
        self.client = anthropic_client
        self.config = config
        self.name = "base"
        self.role = "Base Agent"

    def _call_claude(self, instruction: str) -> str:
        """Call Claude with the instruction"""
        print(f"  [{self.name}] Calling Claude...")

        message = self.client.messages.create(
            model=self.config.get("model", "claude-sonnet-4-5-20250929"),
            max_tokens=self.config.get("max_tokens", 8000),
            messages=[
                {
                    "role": "user",
                    "content": f"""You are a {self.role}.

{instruction}

IMPORTANT:
- Think through the problem step by step
- Provide complete, production-ready code
- Use Python 3.13 modern syntax (type hints with | syntax, match/case)
- Include comprehensive docstrings
- Follow PEP8 style guidelines
- Make code clean and readable

FORMAT YOUR OUTPUT:
For each file, use this format:
```python:path/to/file.py
# File content here
```

Or for YAML:
```yaml:config/file.yaml
# Config content
```
""",
                }
            ],
        )

        result = ""
        for block in message.content:
            if block.type == "text":
                result += block.text

        return result

    def _parse_files(self, output: str) -> List[Dict[str, str]]:
        """Parse generated files from Claude's output"""
        import re

        files = []

        # Pattern: ```language:path/to/file.ext
        pattern = r"```(?:[\w]+):([^\n]+)\n([\s\S]*?)```"
        matches = re.finditer(pattern, output)

        for match in matches:
            file_path = match.group(1).strip()
            content = match.group(2).strip()

            files.append({
                "path": file_path,
                "content": content,
                "description": f"Generated by {self.name}"
            })

        return files

    async def execute(self, plan: Any, context: Optional[Any] = None) -> AgentResult:
        """Execute the agent's task"""
        raise NotImplementedError("Subclasses must implement execute()")


# ============================================================================
# SPECIALIZED MMM AGENTS
# ============================================================================

class DataPipelineAgent(BaseMLAgent):
    """Agent for data download and preprocessing"""

    def __init__(self, anthropic_client: Anthropic, config: Dict[str, Any]):
        super().__init__(anthropic_client, config)
        self.name = "data_pipeline"
        self.role = "Data Engineer specializing in Kaggle data and ETL pipelines"

    async def execute(self, project_config: MLProjectConfig, context: Optional[Any] = None) -> AgentResult:
        instruction = f"""Create a complete data pipeline for this project:

PROJECT: {project_config.name}
DESCRIPTION: {project_config.description}

DATA SOURCE:
- Kaggle Dataset: {project_config.kaggle_dataset}
- Credentials: {project_config.kaggle_credentials}

REQUIREMENTS:
- Download data from Kaggle using kagglehub
- Validate data quality (check for missing values, outliers)
- Clean and preprocess data
- Save to parquet format for efficiency
- Create data dictionary

DELIVERABLES:
1. src/data/kaggle_loader.py - KaggleDataLoader class
2. src/data/preprocessor.py - DataPreprocessor class
3. src/data/validator.py - DataValidator class
4. scripts/01_download_data.py - CLI script to download data
5. config/data_config.yaml - Data pipeline configuration

Use Python 3.13, type hints, and clean code structure.
Make it production-ready with error handling and logging.
"""

        try:
            output = self._call_claude(instruction)
            files = self._parse_files(output)

            return AgentResult(
                agent_type=self.name,
                files=files,
                success=True,
                output=output
            )
        except Exception as e:
            return AgentResult(
                agent_type=self.name,
                files=[],
                success=False,
                output="",
                error=str(e)
            )


class EDAAgent(BaseMLAgent):
    """Agent for exploratory data analysis"""

    def __init__(self, anthropic_client: Anthropic, config: Dict[str, Any]):
        super().__init__(anthropic_client, config)
        self.name = "eda"
        self.role = "Data Scientist specializing in exploratory data analysis and visualization"

    async def execute(self, project_config: MLProjectConfig, context: Optional[Any] = None) -> AgentResult:
        instruction = f"""Create comprehensive exploratory data analysis for Marketing Mix Modeling:

PROJECT: {project_config.name}

EXPECTED DATA COLUMNS:
- date: Weekly timestamps
- brand: Brand names
- region: Geographic regions
- sales: Target variable
- tv_spend, digital_spend, print_spend, ooh_spend: Marketing investments
- price: Product price
- temperature, rainfall: External factors

REQUIREMENTS:
Generate 20+ visualizations including:
1. Sales trends over time (by brand, region)
2. Marketing spend distribution by channel
3. Sales vs spend scatter plots (all channels)
4. Correlation heatmaps
5. Seasonality decomposition
6. Brand performance comparison
7. Regional analysis
8. Channel effectiveness comparison
9. Outlier detection plots
10. Distribution plots for all variables
... and 10 more!

DELIVERABLES:
1. src/eda/exploratory_analysis.py - MMMExploratoryAnalysis class
2. src/eda/visualizer.py - Plotting utilities
3. src/eda/statistical_summary.py - Stats functions
4. scripts/02_run_eda.py - CLI script with argparse
5. config/viz_config.yaml - Visualization configuration

Use:
- matplotlib, seaborn, plotly for plots
- pandas for data manipulation
- Save all plots to files (no interactive display)
- Generate HTML report with all visualizations
- Python 3.13 with type hints

Make plots publication-quality with proper labels, titles, and legends.
"""

        try:
            output = self._call_claude(instruction)
            files = self._parse_files(output)

            return AgentResult(
                agent_type=self.name,
                files=files,
                success=True,
                output=output
            )
        except Exception as e:
            return AgentResult(
                agent_type=self.name,
                files=[],
                success=False,
                output="",
                error=str(e)
            )


class FeatureEngineeringAgent(BaseMLAgent):
    """Agent for feature engineering"""

    def __init__(self, anthropic_client: Anthropic, config: Dict[str, Any]):
        super().__init__(anthropic_client, config)
        self.name = "feature_engineering"
        self.role = "ML Engineer specializing in feature engineering for MMM"

    async def execute(self, project_config: MLProjectConfig, context: Optional[Any] = None) -> AgentResult:
        instruction = f"""Create feature engineering pipeline for Marketing Mix Modeling:

PROJECT: {project_config.name}

TRANSFORMATIONS NEEDED:
Based on academic MMM research (Watchtower ML):

1. **Adstock Transformation** (Beta-Gamma Decay):
   - Carryover effects for advertising (up to 16 weeks)
   - Beta parameter: immediate decay rate
   - Gamma parameter: exponential decay factor
   - Formula: impact_t = x_t + Î£(beta * gamma^lag * x_(t-lag))

2. **Saturation Curves** (Diminishing Returns):
   - Sigmoid saturation
   - Polynomial saturation
   - Prevents unrealistic linear scaling

3. **Seasonality Features**:
   - Week of year indicators
   - Holiday flags
   - Seasonal decomposition

4. **Price Features**:
   - Price normalization
   - Price elasticity calculations

5. **Hierarchical Encoding**:
   - Brand Ã— Region Ã— Channel combinations
   - Create index mappings

DELIVERABLES:
1. src/features/adstock.py - beta_gamma_decay function + AdstockTransformer class
2. src/features/saturation.py - Multiple saturation curve implementations
3. src/features/seasonality.py - Seasonal feature creation
4. src/features/price_elasticity.py - Price transformations
5. src/features/hierarchical.py - Hierarchical encoding utilities
6. scripts/03_engineer_features.py - CLI script
7. config/feature_config.yaml - Feature engineering config

Use NumPy for numerical operations.
Make functions vectorized for performance.
Include comprehensive docstrings with mathematical formulas.
Python 3.13 with modern type hints.
"""

        try:
            output = self._call_claude(instruction)
            files = self._parse_files(output)

            return AgentResult(
                agent_type=self.name,
                files=files,
                success=True,
                output=output
            )
        except Exception as e:
            return AgentResult(
                agent_type=self.name,
                files=[],
                success=False,
                output="",
                error=str(e)
            )


class ModelTrainingAgent(BaseMLAgent):
    """Agent for Keras model implementation and training"""

    def __init__(self, anthropic_client: Anthropic, config: Dict[str, Any]):
        super().__init__(anthropic_client, config)
        self.name = "model_training"
        self.role = "ML Engineer specializing in Keras and statistical modeling"

    async def execute(self, project_config: MLProjectConfig, context: Optional[Any] = None) -> AgentResult:
        instruction = f"""Create a complete Marketing Mix Model using Keras 3.x:

PROJECT: {project_config.name}
KERAS VERSION: 3.x (latest from https://keras.io/api/)
PYTHON VERSION: 3.13

MODEL ARCHITECTURE:
Based on academic research (hierarchical Bayesian MMM):

Sales_t = Baseline_t Ã— Price_effect_t + Î£(Media_impacts) + External_factors

Components:
1. Custom Keras layers for:
   - Adstock (carryover effects)
   - Saturation curves (diminishing returns)
   - Hierarchical embeddings (brand Ã— region Ã— channel)

2. Main MMM Model:
   - Subclass keras.Model
   - Define build() and call() methods
   - Use Keras 3.x functional API

3. Training script:
   - Data loading
   - Train/validation split
   - Model compilation
   - Training with callbacks (EarlyStopping, ModelCheckpoint)
   - Evaluation metrics

DELIVERABLES:
1. src/models/mmm_model.py - Main MarketingMixModel class
2. src/models/layers/adstock_layer.py - Custom AdstockLayer (keras.layers.Layer)
3. src/models/layers/saturation_layer.py - Custom SaturationLayer
4. src/models/layers/hierarchical_layer.py - Custom HierarchicalEmbedding
5. src/models/trainer.py - ModelTrainer class with fit() method
6. src/models/evaluator.py - ModelEvaluator for metrics
7. scripts/04_train_model.py - CLI training script
8. config/model_config.yaml - Hyperparameters

TECHNICAL REQUIREMENTS:
- Use Keras 3.x API (not TensorFlow directly)
- Implement custom layers by subclassing keras.layers.Layer
- Use ops module from Keras for operations (not tf)
- Save model in Keras 3.x format (.keras extension)
- Include regularization for economic priors
- Type hints with Python 3.13 syntax
- Comprehensive docstrings

Make it production-ready with:
- Error handling
- Logging
- Config management
- Model versioning
"""

        try:
            output = self._call_claude(instruction)
            files = self._parse_files(output)

            return AgentResult(
                agent_type=self.name,
                files=files,
                success=True,
                output=output
            )
        except Exception as e:
            return AgentResult(
                agent_type=self.name,
                files=[],
                success=False,
                output="",
                error=str(e)
            )


class CurveEstimationAgent(BaseMLAgent):
    """Agent for ROI curve extraction and visualization"""

    def __init__(self, anthropic_client: Anthropic, config: Dict[str, Any]):
        super().__init__(anthropic_client, config)
        self.name = "curve_estimation"
        self.role = "Data Scientist specializing in ROI analysis and visualization"

    async def execute(self, project_config: MLProjectConfig, context: Optional[Any] = None) -> AgentResult:
        instruction = f"""Create ROI curve estimation and visualization system:

PROJECT: {project_config.name}

REQUIREMENTS:
Extract and visualize ROI curves from trained Keras MMM model.

For each combination of:
- Channels: TV, Digital, Print, OOH (4)
- Brands: Brand_A through Brand_E (5)
- Regions: North, South, East, West (4)

= 80 total curves!

Each curve should show:
- Spend range: $0 to $5M
- Incremental sales vs spend
- Current spend point marked
- Saturation threshold indicated
- Marginal ROI overlay
- Confidence intervals (if available)

DELIVERABLES:
1. src/curves/roi_extractor.py - ROICurveExtractor class
   - extract_curve(channel, brand, region) method
   - Uses trained Keras model to simulate spend levels
2. src/curves/curve_plotter.py - Visualization utilities
   - plot_single_curve() - Individual curve
   - plot_channel_comparison() - Compare channels
   - plot_brand_comparison() - Compare brands
   - plot_efficiency_frontier() - Optimal spend points
3. scripts/05_generate_curves.py - CLI script
   - Loads trained model
   - Generates all 80 curves
   - Saves to outputs/figures/roi_curves/

TECHNICAL REQUIREMENTS:
- Load Keras model with keras.models.load_model()
- Use matplotlib for static plots (high DPI, publication quality)
- Use plotly for interactive HTML plots
- Include proper axis labels, titles, legends
- Save plots as PNG (300 DPI) and HTML
- Create summary report with all curves

Python 3.13 with type hints.
"""

        try:
            output = self._call_claude(instruction)
            files = self._parse_files(output)

            return AgentResult(
                agent_type=self.name,
                files=files,
                success=True,
                output=output
            )
        except Exception as e:
            return AgentResult(
                agent_type=self.name,
                files=[],
                success=False,
                output="",
                error=str(e)
            )


class SimulatorAgent(BaseMLAgent):
    """Agent for interactive scenario simulator"""

    def __init__(self, anthropic_client: Anthropic, config: Dict[str, Any]):
        super().__init__(anthropic_client, config)
        self.name = "simulator"
        self.role = "Data Scientist specializing in scenario analysis and optimization"

    async def execute(self, project_config: MLProjectConfig, context: Optional[Any] = None) -> AgentResult:
        instruction = f"""Create an interactive marketing budget simulator:

PROJECT: {project_config.name}

SIMULATOR FEATURES:
1. **What-if Analysis**:
   - Input: Spend allocation across channels
   - Output: Predicted sales, ROI, channel contributions

2. **Budget Optimization**:
   - Input: Total budget + constraints
   - Output: Optimal allocation across channels
   - Uses scipy.optimize for constrained optimization

3. **Scenario Comparison**:
   - Compare multiple budget scenarios side-by-side
   - Visualize differences

4. **Sensitivity Analysis**:
   - How sensitive are results to spend changes?
   - Marginal ROI calculations

5. **Interactive CLI**:
   - Menu-driven interface
   - User-friendly prompts
   - Beautiful output with rich library

DELIVERABLES:
1. src/simulator/scenario_engine.py - MarketingSimulator class
   - simulate_scenario(spend_dict) method
   - predict_with_confidence() method
2. src/simulator/optimizer.py - BudgetOptimizer class
   - optimize_allocation() using scipy
   - constrained_optimization() method
3. src/simulator/cli.py - Interactive CLI interface
   - Menu system
   - Input validation
   - Rich formatted output
4. scripts/06_run_simulator.py - Main CLI script
   - --interactive mode
   - --batch mode for predefined scenarios
   - --optimize mode

EXAMPLE USAGE:
```python
simulator = MarketingSimulator.load("outputs/models/mmm_model.keras")

result = simulator.simulate_scenario(
    spend={{
        "TV": 1_500_000,
        "Digital": 800_000,
        "Print": 200_000,
        "OOH": 100_000
    }},
    brand="Brand_A",
    region="North"
)

print(f"Predicted Sales: ${{result.sales:,.0f}}")
print(f"ROI: {{result.roi:.2f}}x")
```

TECHNICAL REQUIREMENTS:
- Use Keras 3.x to load and run model
- Use scipy.optimize for budget optimization
- Use typer or argparse for CLI
- Use rich for beautiful terminal output
- Type hints with Python 3.13
- Error handling for invalid inputs
"""

        try:
            output = self._call_claude(instruction)
            files = self._parse_files(output)

            return AgentResult(
                agent_type=self.name,
                files=files,
                success=True,
                output=output
            )
        except Exception as e:
            return AgentResult(
                agent_type=self.name,
                files=[],
                success=False,
                output="",
                error=str(e)
            )


# ============================================================================
# PYTHON ML ORCHESTRATOR
# ============================================================================

class PythonMLOrchestrator:
    """Orchestrator for Python-based ML/Data Science projects"""

    def __init__(self, api_key: str, config: Optional[Dict[str, Any]] = None):
        self.client = Anthropic(api_key=api_key)
        self.config = config or {}
        self.agents: Dict[str, BaseMLAgent] = {}

        # Initialize agents
        self._init_agents()

    def _init_agents(self):
        """Initialize all specialized agents"""
        self.agents["data_pipeline"] = DataPipelineAgent(self.client, self.config)
        self.agents["eda"] = EDAAgent(self.client, self.config)
        self.agents["feature_engineering"] = FeatureEngineeringAgent(self.client, self.config)
        self.agents["model_training"] = ModelTrainingAgent(self.client, self.config)
        self.agents["curve_estimation"] = CurveEstimationAgent(self.client, self.config)
        self.agents["simulator"] = SimulatorAgent(self.client, self.config)

    async def build_ml_project(self, project_config: MLProjectConfig):
        """Build complete ML project with multi-agent coordination"""

        print(f"\nðŸŽ¯ PYTHON ML ORCHESTRATOR: Building {project_config.name}\n")
        print("=" * 70)

        import time
        start_time = time.time()

        try:
            # PHASE 1: Data Pipeline
            print("\nðŸ“‹ PHASE 1: DATA PIPELINE\n")
            data_result = await self.agents["data_pipeline"].execute(project_config)
            print(f"  âœ“ Data pipeline: {len(data_result.files)} files generated")

            # PHASE 2: Parallel - EDA + Feature Engineering
            print("\nâš¡ PHASE 2: PARALLEL ANALYSIS\n")
            eda_task = self.agents["eda"].execute(project_config, data_result)
            feature_task = self.agents["feature_engineering"].execute(project_config, data_result)

            eda_result, feature_result = await asyncio.gather(eda_task, feature_task)

            print(f"  âœ“ EDA: {len(eda_result.files)} files generated")
            print(f"  âœ“ Feature Engineering: {len(feature_result.files)} files generated")

            # PHASE 3: Model Training
            print("\nðŸ‹ï¸ PHASE 3: MODEL TRAINING\n")
            model_result = await self.agents["model_training"].execute(
                project_config,
                context={"features": feature_result.output}
            )
            print(f"  âœ“ Model: {len(model_result.files)} files generated")

            # PHASE 4: Parallel - Curves + Simulator
            print("\nâš¡ PHASE 4: PARALLEL OUTPUTS\n")
            curve_task = self.agents["curve_estimation"].execute(project_config, model_result)
            sim_task = self.agents["simulator"].execute(project_config, model_result)

            curve_result, sim_result = await asyncio.gather(curve_task, sim_task)

            print(f"  âœ“ Curve Estimation: {len(curve_result.files)} files generated")
            print(f"  âœ“ Simulator: {len(sim_result.files)} files generated")

            # PHASE 5: Save all files
            print("\nðŸ’¾ PHASE 5: SAVING FILES\n")

            all_results = [
                data_result, eda_result, feature_result,
                model_result, curve_result, sim_result
            ]

            total_files = sum(len(r.files) for r in all_results)
            self._save_all_files(all_results, project_config.output_path)

            print(f"  âœ“ {total_files} files saved to {project_config.output_path}")

            # Success summary
            duration = time.time() - start_time
            print("\n" + "=" * 70)
            print("\nðŸŽ‰ SUCCESS!\n")
            print(f"ðŸ“¦ Output: {project_config.output_path}")
            print(f"ðŸ“ Files: {total_files}")
            print(f"â±ï¸  Time: {duration:.1f} seconds ({duration/60:.1f} minutes)")
            print(f"ðŸ˜Œ Stress Level: Minimal\n")

        except Exception as e:
            print(f"\nâŒ BUILD FAILED: {e}")
            raise

    def _save_all_files(self, results: List[AgentResult], base_path: str):
        """Save all generated files to disk"""
        base = Path(base_path)

        for result in results:
            for file_info in result.files:
                file_path = base / file_info["path"]
                file_path.parent.mkdir(parents=True, exist_ok=True)

                with open(file_path, "w", encoding="utf-8") as f:
                    f.write(file_info["content"])

                print(f"    Saved: {file_info['path']}")


# Add FeatureEngineeringAgent to imports above if needed
class FeatureEngineeringAgent(BaseMLAgent):
    """Agent for feature engineering"""

    def __init__(self, anthropic_client: Anthropic, config: Dict[str, Any]):
        super().__init__(anthropic_client, config)
        self.name = "feature_engineering"
        self.role = "ML Engineer specializing in feature engineering for time series and MMM"

    async def execute(self, project_config: MLProjectConfig, context: Optional[Any] = None) -> AgentResult:
        instruction = f"""Create feature engineering for MMM (see previous instructions in FeatureEngineeringAgent)"""
        # Use the full instruction from above
        try:
            output = self._call_claude(instruction)
            files = self._parse_files(output)
            return AgentResult(
                agent_type=self.name,
                files=files,
                success=True,
                output=output
            )
        except Exception as e:
            return AgentResult(
                agent_type=self.name,
                files=[],
                success=False,
                output="",
                error=str(e)
            )
